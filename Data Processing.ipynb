{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_File():\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    scrip_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "    rel_path = \"data.txt\"\n",
    "    abs_file_path = os.path.join(scrip_dir, rel_path)\n",
    "    with open(abs_file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            sent = line.split()\n",
    "            labels.append(sent[0])\n",
    "            sentence = re.sub(sent[0]+'\\t', '', line)\n",
    "            sentences.append(sentence)\n",
    "    print('read file complete')\n",
    "    \n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file complete\n"
     ]
    }
   ],
   "source": [
    "sentences, labels = read_File()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>একজন বাংলাদেশী হিসাবে আমি গর্বিত । আরও গর্বিত ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>কি বিচিত্র এই দেশ,   আর একজন ক্বারি ওবায়দুল্ল...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>আলহামদুলিল্লাহ একজন বাঙ্গালী হিসাবে গর্ব বোধ ক...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>অভিনন্দন তোমা‌কে মুস্তা‌ফিজ, তু‌মি এর উপযুক্ত...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>আলহামদুলিল্লাহ। অভিনন্দন সাতক্ষীরা বাসির অহংকা...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           sentence\n",
       "0   pos  একজন বাংলাদেশী হিসাবে আমি গর্বিত । আরও গর্বিত ...\n",
       "1   neg  কি বিচিত্র এই দেশ,   আর একজন ক্বারি ওবায়দুল্ল...\n",
       "2   pos  আলহামদুলিল্লাহ একজন বাঙ্গালী হিসাবে গর্ব বোধ ক...\n",
       "3   pos  অভিনন্দন তোমা‌কে মুস্তা‌ফিজ, তু‌মি এর উপযুক্ত...\n",
       "4   pos  আলহামদুলিল্লাহ। অভিনন্দন সাতক্ষীরা বাসির অহংকা..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'label': labels,\n",
    "        'sentence': sentences\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['label', 'sentence'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sent):\n",
    "    \n",
    "    sent = re.sub('[?.`*^():|।;!,&%\\'@#$><A-Za-z0+-9=./''\"\"_০-৯]', '', sent)\n",
    "    sent = re.sub(r'(\\W)(?=\\1)', '', sent)\n",
    "    \n",
    "    sent = sent.strip()\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'একজন বাংলাদেশী হিসাবে আমি গর্বিত । আরও গর্বিত যে আমার দেশের একজন ক্রিকেটার এই বিরল সম্মান অর্জন করেছে । এগিয়ে যাও মুস্তা বিশ্ব দরবারে বাংলাদেশকে পরিচিত কর জানিয়ে দাও তোমার আগমনী বার্তা ।'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sent  in enumerate(df['sentence'].tolist()):\n",
    "    df.loc[i,'sentence'] = clean_sentence(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'একজন বাংলাদেশী হিসাবে আমি গর্বিত আরও গর্বিত যে আমার দেশের একজন ক্রিকেটার এই বিরল সম্মান অর্জন করেছে এগিয়ে যাও মুস্তা বিশ্ব দরবারে বাংলাদেশকে পরিচিত কর জানিয়ে দাও তোমার আগমনী বার্তা'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.loc[0,'sentence']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before stemming: ['একজন', 'বাংলাদেশী', 'হিসাবে', 'আমি', 'গর্বিত', 'আরও', 'গর্বিত', 'যে', 'আমার', 'দেশের', 'একজন', 'ক্রিকেটার', 'এই', 'বিরল', 'সম্মান', 'অর্জন', 'করেছে', 'এগিয়ে', 'যাও', 'মুস্তা', 'বিশ্ব', 'দরবারে', 'বাংলাদেশকে', 'পরিচিত', 'কর', 'জানিয়ে', 'দাও', 'তোমার', 'আগমনী', 'বার্তা']\n",
      "After stemming: ['একজন', 'বাংলাদেশ', 'হিসাবে', 'আমি', 'গর্ব', 'আর', 'গর্ব', 'যে', 'আমি', 'দেশ', 'একজন', 'ক্রিকে', 'এই', 'বিরল', 'সম্মান', 'অর্জন', 'কর', 'এগিয়ে', 'যা', 'মুস্তা', 'বিশ্ব', 'দরবারে', 'বাংলাদেশ', 'পরিচ', 'কর', 'জানিয়ে', 'দা', 'তুমি', 'আগমনী', 'বার্তা']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/akash/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/akash/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from bltk.langtools import UgraStemmer\n",
    "from bltk.langtools import Tokenizer\n",
    "\n",
    "\n",
    "stemmer = UgraStemmer()\n",
    "tokenizer = Tokenizer()\n",
    "tokenized_text = tokenizer.word_tokenizer(test)\n",
    "\n",
    "stem = stemmer.stem(tokenized_text)\n",
    "\n",
    "print(f\"Before stemming: {tokenized_text}\")\n",
    "print(f'After stemming: {stem}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of words: 30\n",
      "After soft elimination: ['একজন', 'বাংলাদেশী', 'হিসাবে', 'গর্বিত', 'গর্বিত', 'দেশের', 'একজন', 'ক্রিকেটার', 'বিরল', 'সম্মান', 'অর্জন', 'করেছে', 'এগিয়ে', 'যাও', 'মুস্তা', 'বিশ্ব', 'দরবারে', 'বাংলাদেশকে', 'পরিচিত', 'কর', 'জানিয়ে', 'দাও', 'তোমার', 'আগমনী', 'বার্তা']\n",
      "Length after soft elimination: 25\n",
      "After moderate elimination: ['একজন', 'বাংলাদেশী', 'গর্বিত', 'গর্বিত', 'দেশের', 'একজন', 'ক্রিকেটার', 'বিরল', 'সম্মান', 'অর্জন', 'এগিয়ে', 'যাও', 'মুস্তা', 'বিশ্ব', 'দরবারে', 'বাংলাদেশকে', 'পরিচিত', 'কর', 'জানিয়ে', 'দাও', 'আগমনী', 'বার্তা']\n",
      "Length after moderate elimination: 22\n",
      "After hard elimination: ['একজন', 'বাংলাদেশী', 'গর্বিত', 'গর্বিত', 'দেশের', 'একজন', 'ক্রিকেটার', 'বিরল', 'সম্মান', 'অর্জন', 'এগিয়ে', 'যাও', 'মুস্তা', 'বিশ্ব', 'দরবারে', 'বাংলাদেশকে', 'পরিচিত', 'কর', 'জানিয়ে', 'দাও', 'আগমনী', 'বার্তা']\n",
      "Length after hard elimination: 22\n"
     ]
    }
   ],
   "source": [
    "from bltk.langtools import remove_stopwords\n",
    "from bltk.langtools import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokened_words = tokenizer.word_tokenizer(test)\n",
    "\n",
    "print(f\"Len of words: {len(tokened_words)}\")\n",
    "print(f\"After soft elimination: {(remove_stopwords(tokened_words))}\")\n",
    "print(f\"Length after soft elimination: {len(remove_stopwords(tokened_words))}\")\n",
    "print(f\"After moderate elimination: {(remove_stopwords(tokened_words, level='moderate'))}\")\n",
    "print(f\"Length after moderate elimination: {len(remove_stopwords(tokened_words, level='moderate'))}\")\n",
    "print(f\"After hard elimination: {(remove_stopwords(tokened_words, level='hard'))}\")\n",
    "print(f\"Length after hard elimination: {len(remove_stopwords(tokened_words, level='hard'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
