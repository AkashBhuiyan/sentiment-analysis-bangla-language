{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_File():\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    scrip_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "    rel_path = \"data.txt\"\n",
    "    abs_file_path = os.path.join(scrip_dir, rel_path)\n",
    "    with open(abs_file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            sent = line.split()\n",
    "            labels.append(sent[0])\n",
    "            sentence = re.sub(sent[0]+'\\t', '', line)\n",
    "            sentences.append(sentence)\n",
    "    print('read file complete')\n",
    "    \n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file complete\n"
     ]
    }
   ],
   "source": [
    "sentences, labels = read_File()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>একজন বাংলাদেশী হিসাবে আমি গর্বিত । আরও গর্বিত ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>কি বিচিত্র এই দেশ,   আর একজন ক্বারি ওবায়দুল্ল...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>আলহামদুলিল্লাহ একজন বাঙ্গালী হিসাবে গর্ব বোধ ক...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>অভিনন্দন তোমা‌কে মুস্তা‌ফিজ, তু‌মি এর উপযুক্ত...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>আলহামদুলিল্লাহ। অভিনন্দন সাতক্ষীরা বাসির অহংকা...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           sentence\n",
       "0   pos  একজন বাংলাদেশী হিসাবে আমি গর্বিত । আরও গর্বিত ...\n",
       "1   neg  কি বিচিত্র এই দেশ,   আর একজন ক্বারি ওবায়দুল্ল...\n",
       "2   pos  আলহামদুলিল্লাহ একজন বাঙ্গালী হিসাবে গর্ব বোধ ক...\n",
       "3   pos  অভিনন্দন তোমা‌কে মুস্তা‌ফিজ, তু‌মি এর উপযুক্ত...\n",
       "4   pos  আলহামদুলিল্লাহ। অভিনন্দন সাতক্ষীরা বাসির অহংকা..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'label': labels,\n",
    "        'sentence': sentences\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['label', 'sentence'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sent):\n",
    "    \n",
    "    sent = re.sub('[?.`*^():|।;!,&%\\'@#$><A-Za-z0+-9=./''\"\"_০-৯]', '', sent)\n",
    "    sent = re.sub(r'(\\W)(?=\\1)', '', sent)\n",
    "    \n",
    "    sent = sent.strip()\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'একজন বাংলাদেশী হিসাবে আমি গর্বিত । আরও গর্বিত যে আমার দেশের একজন ক্রিকেটার এই বিরল সম্মান অর্জন করেছে । এগিয়ে যাও মুস্তা, বিশ্ব দরবারে বাংলাদেশকে পরিচিত কর, জানিয়ে দাও তোমার আগমনী বার্তা ।\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sent  in enumerate(df['sentence'].tolist()):\n",
    "    df.loc[i,'sentence'] = clean_sentence(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'একজন বাংলাদেশী হিসাবে আমি গর্বিত আরও গর্বিত যে আমার দেশের একজন ক্রিকেটার এই বিরল সম্মান অর্জন করেছে এগিয়ে যাও মুস্তা বিশ্ব দরবারে বাংলাদেশকে পরিচিত কর জানিয়ে দাও তোমার আগমনী বার্তা'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.loc[0,'sentence']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/akash/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/akash/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from bltk.langtools import UgraStemmer\n",
    "from bltk.langtools import Tokenizer\n",
    "\n",
    "\n",
    "stemmer = UgraStemmer()\n",
    "def strammer_data(tokenized_text):\n",
    "    stem = stemmer.stem(tokenized_text)\n",
    "    print(f'After stemming: {stem}')\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bltk.langtools import remove_stopwords\n",
    "\n",
    "def remove_stopwords_func(tokened_words, level=None):\n",
    "    stop_word_removed_data = remove_stopwords(tokened_words, level=level)\n",
    "    print(len(stop_word_removed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
